{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSI Project 4 - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first import libraries\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, r2_score, mean_squared_error, explained_variance_score\n",
    "from warnings import simplefilter\n",
    "# Optionally turn off warnings once the models are producing good results\n",
    "#   non convergence may mean the result is not perfect, but it might be good enough\n",
    "# Credit to Jamie Shaffer\n",
    "simplefilter(\"ignore\", category=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_explorer:\n",
    "    # This class takes in a DataFrame and then does some initial exploration\n",
    "    def __init__(self, path):\n",
    "        # This initalizes and loads all our past datasets\n",
    "        self.dframe = pd.read_csv(path)\n",
    "        self.dtypes = self.dframe.dtypes\n",
    "        self.shape = self.dframe.shape\n",
    "        self.nulls = self.dframe.isnull().mean()\n",
    "    \n",
    "    # This method explores the dataframe dtypes and null values\n",
    "    def explore(self):\n",
    "        # Let's check out the shape of our DataFrame    \n",
    "        print(f'DataFrame has {self.dframe.shape[1]} columns and {self.dframe.shape[0]} rows.')   \n",
    "        \n",
    "        # First we'll look for null values and Data Types\n",
    "        i = 1\n",
    "        for item1, item2 in zip(self.nulls, self.dtypes):\n",
    "            p = 0\n",
    "\n",
    "            if item1 != 0:\n",
    "                print(f'Column {i} has {item1} null items')\n",
    "                p += 1\n",
    "            print(f'Column {i} is {item2}')\n",
    "            i += 1   \n",
    "        if p == 0:\n",
    "            print(f'DataFrame has zero null values.')\n",
    "            \n",
    "    # Drop selected columns\n",
    "    def col_drop(self, drop_list, inplace = True):\n",
    "        self.dframe.drop(columns=drop_list, inplace=True)\n",
    "    \n",
    "    # Check out why an object column isn't numeric\n",
    "    def num_check(self, column_name):\n",
    "        print(self.dframe[self.dframe[column_name].str.isnumeric() == False])\n",
    "     \n",
    "    # Displays a column is Descending Order\n",
    "    def view_asc(self, column_name, asc = False):\n",
    "        temp = self.dframe[column_name].sort_values(ascending = asc)\n",
    "        return temp\n",
    "    \n",
    "    # This will set any column values you choose in your selected column to NAN\n",
    "    def col_nan(self, column_name, s):\n",
    "        self.dframe[column_name].apply(lambda x: np.nan if x == s else int(x))\n",
    "    \n",
    "    # This will show us what the shape of the DFrame will be if we drop all NAN values\n",
    "    def s_if_drop(self):\n",
    "        self.dframe.dropna().shape\n",
    "    \n",
    "    # This method will fill any NAN value in the DataFrame with 0\n",
    "    def fill_na(self):\n",
    "        self.dframe.fillna(value = 0)\n",
    "    \n",
    "    # This will build a new DataFrame with just the columns we desire\n",
    "    def df_builder(self, column_list):\n",
    "        new_df = pd.DataFrame()\n",
    "        for item in column_list:\n",
    "            new_df[item] = self.dframe[item]\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data_explorer class\n",
    "df_o = data_explorer('/data/hackathon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deap copy of our dataframe\n",
    "df = df_o.dframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class does the following:\n",
    "# Does a train/test/split on an input dataframe, with the features and target taken as input\n",
    "# It then scales the data using StandardScaler\n",
    "class analyzer:\n",
    "    def __init__(self, df, features, target):\n",
    "        self.df = df\n",
    "        self.X = self.df[features]\n",
    "        self.y = self.df[target]\n",
    "        # This splits our data for testing     \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.33, random_state=42, stratify=self.y)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        # Scale our data.\n",
    "        sc = StandardScaler()\n",
    "        self.Z_train = sc.fit_transform(self.X_train)\n",
    "        self.Z_test = sc.transform(self.X_test)\n",
    "        \n",
    "    def go(self):\n",
    "        # This method runs four models through pipeslines\n",
    "        \n",
    "        \n",
    "        # Model #1\n",
    "        # We'll start out by running a LogisticRegression\n",
    "        print('Logistic Regression:')\n",
    "        print('-------------- \\n')\n",
    "        c = np.logspace(.001, 1, 100)\n",
    "        # Set params\n",
    "        pipe_params = {\n",
    "            'C' : c\n",
    "            }\n",
    "        # Gonna start with LogisticRegression\n",
    "        lr = LogisticRegression()\n",
    "        gs = GridSearchCV(estimator = lr, param_grid = pipe_params, cv = 5, n_jobs=-1)\n",
    "        gs.fit(self.Z_train, self.y_train)\n",
    "        gs_model = gs.best_estimator_\n",
    "        preds = gs_model.predict(self.Z_test)\n",
    "        \n",
    "        # Calculate and print our metrics\n",
    "        print(f'Best Score: {np.round(gs.best_score_,3)} \\n')\n",
    "\n",
    "        print(f'X_train, y_train Score: {np.round(gs_model.score(self.Z_train, self.y_train), 3)}')\n",
    "        print(f'X_test, y_test Score: {np.round(gs_model.score(self.Z_test, self.y_test), 3)} \\n')\n",
    "\n",
    "        cm = confusion_matrix(self.y_test, preds)\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        print(f'True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN} \\n')\n",
    "\n",
    "        print(f'{classification_report(self.y_test, preds)} \\n')\n",
    "\n",
    "        print('--------------------------------- \\n')\n",
    "        print('1 of 3  Models Finished \\n')  \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Model #2\n",
    "        # Now we'll run MultinomialNB\n",
    "        print(f'MultinomialNB')\n",
    "        print('-------------- \\n')\n",
    "        \n",
    "        alphas= np.linspace(.001, 1, 100)\n",
    "        pipe = Pipeline([\n",
    "            ('mnb', MultinomialNB())\n",
    "        ])\n",
    "\n",
    "        # Set up pipeline parameters\n",
    "        pipe_params = {\n",
    "            'mnb__alpha' : alphas\n",
    "#             'mnb__fit_prior' : [True, False]\n",
    "        }\n",
    "        \n",
    "        gs = GridSearchCV(pipe,\n",
    "        pipe_params,\n",
    "        cv = 5,\n",
    "        n_jobs=-1) # 5-fold cross-validation.\n",
    "        \n",
    "        # Fit GridSearch to training data.\n",
    "        gs.fit(self.X_train, self.y_train);\n",
    "        gs_model = gs.best_estimator_\n",
    "        preds = gs_model.predict(self.X_test)\n",
    "\n",
    "        # Calculate and print our metrics\n",
    "        print(f'Best Score: {np.round(gs.best_score_,3)} \\n')\n",
    "\n",
    "        print(f'X_train, y_train Score: {np.round(gs_model.score(self.X_train, self.y_train),3)}')\n",
    "        print(f'X_test, y_test Score: {np.round(gs_model.score(self.X_test, self.y_test),3)} \\n')\n",
    "\n",
    "        cm = confusion_matrix(self.y_test, preds)\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        print(f'True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN} \\n')\n",
    "\n",
    "        print(f'{classification_report(self.y_test, preds)} \\n')\n",
    "\n",
    "        print('--------------------------------- \\n')        \n",
    "        print('2 of 3  Models Finished \\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Model #3\n",
    "        # Now we'll run a LinearSVC\n",
    "        print('LinearSVC (This is gonna take a while...):')\n",
    "        print('--------- \\n')\n",
    "        \n",
    "        pgrid = {\"C\": np.linspace(0.0001, 1, 20)}\n",
    "\n",
    "        svc = LinearSVC(max_iter = 5000)\n",
    "        gs = GridSearchCV(estimator = svc, param_grid = pgrid, cv = 5, n_jobs=-1)\n",
    "        gs.fit(self.Z_train, self.y_train)\n",
    "        gs_model = gs.best_estimator_\n",
    "        preds = gs_model.predict(self.Z_test)\n",
    "      \n",
    "\n",
    "        # Calculate and print our metrics\n",
    "        print(f'Best Score: {np.round(gs.best_score_,3)} \\n')\n",
    "\n",
    "        print(f'X_train, y_train Score: {np.round(gs_model.score(self.Z_train, self.y_train), 3)}')\n",
    "        print(f'X_test, y_test Score: {np.round(gs_model.score(self.Z_test, self.y_test), 3)} \\n')\n",
    "\n",
    "        cm = confusion_matrix(self.y_test, preds)\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        print(f'True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN} \\n')\n",
    "\n",
    "        print(f'{classification_report(self.y_test, preds)} \\n')\n",
    "\n",
    "        print('--------------------------------- \\n')     \n",
    "        print('3 of 3  Models Finished \\n')\n",
    "        \n",
    "        \n",
    "        # Model 2\n",
    "        # Now we'll run RandomForestClassifier\n",
    "        print('RandomForestClassifier:')\n",
    "        print('----------------------- \\n')\n",
    "        pgrid = {\n",
    "            'n_estimators':[116],\n",
    "            'max_features':[None],\n",
    "            'max_depth':[11]\n",
    "        }\n",
    "        \n",
    "        rf = RandomForestClassifier()\n",
    "        gs = GridSearchCV(estimator = rf, param_grid = pgrid, cv = 5, n_jobs=-1)\n",
    "        gs.fit(self.Z_train, self.y_train)\n",
    "        gs_model = gs.best_estimator_\n",
    "        preds = gs_model.predict(self.Z_test)\n",
    "        \n",
    "        # Now we'll calculate and print our metrics\n",
    "#         print(f'Best Score: {print(gs.best_score_)} \\n')\n",
    "        print(f'X_train, y_train Score: {np.round(gs_model.score(self.Z_train, self.y_train), 3)}')\n",
    "        print(f'X_test, y_test Score: {np.round(gs_model.score(self.Z_test, self.y_test), 3)} \\n')\n",
    "        \n",
    "        cm = confusion_matrix(self.y_test, preds)\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        \n",
    "        print(f'True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN} \\n')\n",
    "        print(f'{classification_report(self.y_test, preds)} \\n')\n",
    "        print('--------------------------------- \\n')     \n",
    "        print('4 of 4  Models Finished \\n')\n",
    "        \n",
    "        print('Analysis Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our features and our target\n",
    "features = ['age', 'fnlwgt', 'education-num', 'hours-per-week', 'workclass_?', 'workclass_Never-worked', 'workclass_Private', 'workclass_Self-emp-inc',\n",
    "            'workclass_Self-emp-not-inc', 'workclass_Without-pay', 'workclass-govt', 'married', 'single', 'separated', 'US', 'male', 'fnlwgt^2', 'hours-per-week^2']\n",
    "target = 'wage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an analyzer object\n",
    "a_obj = analyzer(df, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "-------------- \n",
      "\n",
      "Best Score: 0.826 \n",
      "\n",
      "X_train, y_train Score: 0.827\n",
      "X_test, y_test Score: 0.827 \n",
      "\n",
      "True Positives: 1358, True Negatives: 7532, False Positives: 626, False Negatives: 1230 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      8158\n",
      "           1       0.68      0.52      0.59      2588\n",
      "\n",
      "    accuracy                           0.83     10746\n",
      "   macro avg       0.77      0.72      0.74     10746\n",
      "weighted avg       0.82      0.83      0.82     10746\n",
      " \n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "1 of 3  Models Finished \n",
      "\n",
      "MultinomialNB\n",
      "-------------- \n",
      "\n",
      "Best Score: 0.379 \n",
      "\n",
      "X_train, y_train Score: 0.379\n",
      "X_test, y_test Score: 0.376 \n",
      "\n",
      "True Positives: 2009, True Negatives: 2033, False Positives: 6125, False Negatives: 579 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.25      0.38      8158\n",
      "           1       0.25      0.78      0.37      2588\n",
      "\n",
      "    accuracy                           0.38     10746\n",
      "   macro avg       0.51      0.51      0.38     10746\n",
      "weighted avg       0.65      0.38      0.38     10746\n",
      " \n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "2 of 3  Models Finished \n",
      "\n",
      "LinearSVC (This is gonna take a while...):\n",
      "--------- \n",
      "\n",
      "Best Score: 0.826 \n",
      "\n",
      "X_train, y_train Score: 0.827\n",
      "X_test, y_test Score: 0.828 \n",
      "\n",
      "True Positives: 1330, True Negatives: 7573, False Positives: 585, False Negatives: 1258 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      8158\n",
      "           1       0.69      0.51      0.59      2588\n",
      "\n",
      "    accuracy                           0.83     10746\n",
      "   macro avg       0.78      0.72      0.74     10746\n",
      "weighted avg       0.82      0.83      0.82     10746\n",
      " \n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "3 of 3  Models Finished \n",
      "\n",
      "RandomForestClassifier:\n",
      "----------------------- \n",
      "\n",
      "X_train, y_train Score: 0.879\n",
      "X_test, y_test Score: 0.829 \n",
      "\n",
      "True Positives: 1434, True Negatives: 7474, False Positives: 684, False Negatives: 1154 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      8158\n",
      "           1       0.68      0.55      0.61      2588\n",
      "\n",
      "    accuracy                           0.83     10746\n",
      "   macro avg       0.77      0.74      0.75     10746\n",
      "weighted avg       0.82      0.83      0.82     10746\n",
      " \n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "4 of 4  Models Finished \n",
      "\n",
      "Analysis Finished\n"
     ]
    }
   ],
   "source": [
    "# Run analysis\n",
    "a_obj.go()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
