{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install regex\n",
    "# pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import unicodedata\n",
    "import datetime\n",
    "import praw\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup    \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords # Import the stopword list\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from warnings import simplefilter\n",
    "# Optionally turn off warnings once the models are producing good results\n",
    "#   non convergence may mean the result is not perfect, but it might be good enough\n",
    "# Credit to Jamie Shaffer\n",
    "simplefilter(\"ignore\", category=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is used to pull data from Reddit and then create a DataFrame, it also loads the lastest csv into a dataframe\n",
    "\n",
    "class reddit_getter:\n",
    "    def __init__(self, sub):\n",
    "        # This initalizes and loads all our past datasets\n",
    "        self.subreddit = sub\n",
    "        self.submits = 1000\n",
    "        self.time_filter = 'day'\n",
    "        self.reddit = praw.Reddit(client_id = 'oZRFffq6V4xYMg',\n",
    "                    client_secret = 'O_p5-j5D3fYEa58nqMOwHnGZw0E',\n",
    "                    username = 'the_illuminati_666',\n",
    "                    user_agent = 'nothing_nefarious')\n",
    "        self.dframe = pd.read_csv('../data_files/combined_reddit_data.csv')\n",
    "    \n",
    "    # This function can be called to pull data from Reddit, provided a submission_getter object has been created\n",
    "    def get(self):\n",
    "        comment_dict = {}\n",
    "        subreddit = self.reddit.subreddit(self.subreddit)\n",
    "        reddit_data = subreddit.top(time_filter = self.time_filter, limit = self.submits)\n",
    "        print(f'Subreddit We Are Mining: {self.subreddit}, Time Filter: {self.time_filter}')\n",
    "        for submission in reddit_data:\n",
    "            # sometimes the submission.stickied method throws an error, we'll use a try and except in case\n",
    "            try:\n",
    "                if not submission.stickied:\n",
    "                    comment_dict.update({submission.id : [submission.title, submission.author, subreddit.title, submission.num_comments, str(self.time_filter)]})          \n",
    "            except:\n",
    "                pass\n",
    "        df = pd.DataFrame.from_dict(data = comment_dict, orient = 'index', columns = ['Submission Title', 'Submission Author', 'Subreddit', 'Number of Comments', 'Time Filter'])\n",
    "        print('Returning DataFrame')\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submission Title</th>\n",
       "      <th>Submission Author</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Time Filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Megathread: House Votes to Impeach President D...</td>\n",
       "      <td>PoliticsModeratorBot</td>\n",
       "      <td>Politics</td>\n",
       "      <td>52218</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virginia governor makes Election Day a holiday...</td>\n",
       "      <td>nclobo</td>\n",
       "      <td>Politics</td>\n",
       "      <td>4158</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Video emerges showing Trump talking about cutt...</td>\n",
       "      <td>Nihilist911</td>\n",
       "      <td>Politics</td>\n",
       "      <td>4785</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Trump administration paid a bankrupt compa...</td>\n",
       "      <td>DaFunkJunkie</td>\n",
       "      <td>Politics</td>\n",
       "      <td>4809</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Removed US coronavirus vaccine director files ...</td>\n",
       "      <td>grepnork</td>\n",
       "      <td>Politics</td>\n",
       "      <td>5089</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Submission Title     Submission Author  \\\n",
       "0  Megathread: House Votes to Impeach President D...  PoliticsModeratorBot   \n",
       "1  Virginia governor makes Election Day a holiday...                nclobo   \n",
       "2  Video emerges showing Trump talking about cutt...           Nihilist911   \n",
       "3  The Trump administration paid a bankrupt compa...          DaFunkJunkie   \n",
       "4  Removed US coronavirus vaccine director files ...              grepnork   \n",
       "\n",
       "  Subreddit  Number of Comments Time Filter  \n",
       "0  Politics               52218         all  \n",
       "1  Politics                4158         all  \n",
       "2  Politics                4785         all  \n",
       "3  Politics                4809         all  \n",
       "4  Politics                5089         all  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_object = reddit_getter('Politics')\n",
    "df = df_object.dframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class cleans and lemmatizes our sentences\n",
    "class clean_sentences:\n",
    "    def __init__(self, df):\n",
    "        s = []\n",
    "\n",
    "        df['Subreddit'] = df['Subreddit'].map({'Politics' : 1, 'Democrats: Stronger Together' : 0})\n",
    "        for item in df['Submission Title']:\n",
    "            \n",
    "            letters = re.sub(\"[^a-zA-Z]\", \" \", item)\n",
    "\n",
    "            words = letters.lower().split()\n",
    "\n",
    "            stops = set(stopwords.words('english'))\n",
    "\n",
    "            more_words = [w for w in words if w not in stops]\n",
    "            \n",
    "            cleaned_sentence = \" \".join(more_words)\n",
    "\n",
    "            s.append(cleaned_sentence)\n",
    "\n",
    "        df['cleaned_submissions'] = s\n",
    "\n",
    "        lems = WordNetLemmatizer()\n",
    "        lemmed = []\n",
    "        for item in df['cleaned_submissions']:\n",
    "            s_temp = \"\"\n",
    "            s1 = item.split()\n",
    "            lem_r = [lems.lemmatize(s) for s in s1]\n",
    "            s_temp = \" \".join(lem_r)\n",
    "            lemmed.append(s_temp)\n",
    "            \n",
    "        df['lemmed'] = lemmed\n",
    "        self.dframe = df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Object\n",
    "df_o = clean_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submission Title</th>\n",
       "      <th>Submission Author</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Time Filter</th>\n",
       "      <th>cleaned_submissions</th>\n",
       "      <th>lemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Megathread: House Votes to Impeach President D...</td>\n",
       "      <td>PoliticsModeratorBot</td>\n",
       "      <td>1</td>\n",
       "      <td>52218</td>\n",
       "      <td>all</td>\n",
       "      <td>megathread house votes impeach president donal...</td>\n",
       "      <td>megathread house vote impeach president donald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virginia governor makes Election Day a holiday...</td>\n",
       "      <td>nclobo</td>\n",
       "      <td>1</td>\n",
       "      <td>4158</td>\n",
       "      <td>all</td>\n",
       "      <td>virginia governor makes election day holiday e...</td>\n",
       "      <td>virginia governor make election day holiday ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Video emerges showing Trump talking about cutt...</td>\n",
       "      <td>Nihilist911</td>\n",
       "      <td>1</td>\n",
       "      <td>4785</td>\n",
       "      <td>all</td>\n",
       "      <td>video emerges showing trump talking cutting pa...</td>\n",
       "      <td>video emerges showing trump talking cutting pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Trump administration paid a bankrupt compa...</td>\n",
       "      <td>DaFunkJunkie</td>\n",
       "      <td>1</td>\n",
       "      <td>4809</td>\n",
       "      <td>all</td>\n",
       "      <td>trump administration paid bankrupt company zer...</td>\n",
       "      <td>trump administration paid bankrupt company zer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Removed US coronavirus vaccine director files ...</td>\n",
       "      <td>grepnork</td>\n",
       "      <td>1</td>\n",
       "      <td>5089</td>\n",
       "      <td>all</td>\n",
       "      <td>removed us coronavirus vaccine director files ...</td>\n",
       "      <td>removed u coronavirus vaccine director file st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Submission Title     Submission Author  \\\n",
       "0  Megathread: House Votes to Impeach President D...  PoliticsModeratorBot   \n",
       "1  Virginia governor makes Election Day a holiday...                nclobo   \n",
       "2  Video emerges showing Trump talking about cutt...           Nihilist911   \n",
       "3  The Trump administration paid a bankrupt compa...          DaFunkJunkie   \n",
       "4  Removed US coronavirus vaccine director files ...              grepnork   \n",
       "\n",
       "   Subreddit  Number of Comments Time Filter  \\\n",
       "0          1               52218         all   \n",
       "1          1                4158         all   \n",
       "2          1                4785         all   \n",
       "3          1                4809         all   \n",
       "4          1                5089         all   \n",
       "\n",
       "                                 cleaned_submissions  \\\n",
       "0  megathread house votes impeach president donal...   \n",
       "1  virginia governor makes election day holiday e...   \n",
       "2  video emerges showing trump talking cutting pa...   \n",
       "3  trump administration paid bankrupt company zer...   \n",
       "4  removed us coronavirus vaccine director files ...   \n",
       "\n",
       "                                              lemmed  \n",
       "0  megathread house vote impeach president donald...  \n",
       "1  virginia governor make election day holiday ex...  \n",
       "2  video emerges showing trump talking cutting pa...  \n",
       "3  trump administration paid bankrupt company zer...  \n",
       "4  removed u coronavirus vaccine director file st...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_o.dframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our variables\n",
    "X = df['lemmed']\n",
    "y = df['Subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4636,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shapes match\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4636,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2365\n",
       "0     741\n",
       "Name: Subreddit, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Everything looks ok\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class runs 4 models, and then prints their metrics\n",
    "class analyzer:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def do_it(self):\n",
    "        \n",
    "        # This methods runs four differant models and then prints out the results\n",
    "        print(f'Starting Analysis, Be Patient... \\n')\n",
    "        \n",
    "\n",
    "        print(f'Running CountVectorizer + LogisticRegression')\n",
    "        print('-------------------------------------------- \\n')\n",
    "        pipe1 = Pipeline([\n",
    "        ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "        ('lr', LogisticRegression())\n",
    "        ])   \n",
    "        \n",
    "        pipe_params = {\n",
    "            'cvec__max_features' : [500, 1000, 1500],\n",
    "            'cvec__min_df' : [2, 3],\n",
    "            'cvec__max_df' : [.9, .95],\n",
    "            'cvec__ngram_range' : [(1, 1), (1, 2)],\n",
    "            'lr__solver' : ['newton-cg', 'lbfgs']\n",
    "            }\n",
    "        gs1 = GridSearchCV(pipe1,\n",
    "        pipe_params,\n",
    "        cv = 5) # 5-fold cross-validation.\n",
    "        \n",
    "        # Fit GridSearch to training data.\n",
    "        gs1.fit(self.X_train, self.y_train);\n",
    "        gs1_model = gs1.best_estimator_\n",
    "        preds1 = gs1_model.predict(self.X_test)\n",
    "        print('1 of 4  Models Finished \\n')\n",
    "        print(f'I Said Be Patient!!! \\n')            \n",
    "            \n",
    "        # Now we'll run CountVectorizer + MultinomialNB\n",
    "        print(f'Running CountVectorizer + MultinomialNB')\n",
    "        print('--------------------------------------- \\n')\n",
    "        pipe2 = Pipeline([\n",
    "            ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "            ('mnb', MultinomialNB())\n",
    "        ])\n",
    "\n",
    "        # Set up pipeline parameters\n",
    "        pipe_params2 = {\n",
    "            'cvec__max_features' : [500, 1000, 1500],\n",
    "            'cvec__min_df' : [2, 3],\n",
    "            'cvec__max_df' : [.9, .95],\n",
    "            'cvec__ngram_range' : [(1, 1), (1, 2)],\n",
    "#             'mnb__alpha': [1.0, 0, .01], \n",
    "            'mnb__fit_prior': [True, False]\n",
    "        }\n",
    "        \n",
    "        gs2 = GridSearchCV(pipe2,\n",
    "        pipe_params2,\n",
    "        cv = 5) # 5-fold cross-validation.\n",
    "        \n",
    "        # Fit GridSearch to training data.\n",
    "        gs2.fit(self.X_train, self.y_train);\n",
    "        gs2_model = gs2.best_estimator_\n",
    "        preds2 = gs2_model.predict(self.X_test)\n",
    "        print('2 of 4  Models Finished \\n')\n",
    "\n",
    "\n",
    "        # Now we'll run TfidfVectorizer + LogisticRegression\n",
    "        print(f'Running TfidfVectorizer + LogisticRegression')\n",
    "        print('-------------------------------------------- \\n')\n",
    "        # Set up pipeline params\n",
    "        pipe3 = Pipeline([\n",
    "        ('tvec', TfidfVectorizer(stop_words = 'english')),\n",
    "        ('lr', LogisticRegression())\n",
    "        ])\n",
    "    \n",
    "\n",
    "        # Set up pipeline params\n",
    "        pipe_params = {\n",
    "            'tvec__max_features': [200, 500],\n",
    "            'tvec__ngram_range' : [(1, 2)],\n",
    "            'lr__solver' : ['lbfgs', 'newton-cg']\n",
    "        }\n",
    "        \n",
    "        gs3 = GridSearchCV(pipe3, # what object are we optimizing?\n",
    "        pipe_params, # what parameters values are we searching?\n",
    "        cv = 5) # 5-fold cross-validation.\n",
    "        \n",
    "        # Fit GridSearch to training data.\n",
    "        gs3.fit(self.X_train, self.y_train);\n",
    "        gs3_model = gs3.best_estimator_\n",
    "        preds3 = gs3_model.predict(self.X_test)\n",
    "        print('3 of 4  Models Finished \\n')\n",
    "\n",
    "\n",
    "        # Now we'll run TfidfVectorizer + MultinomialNB\n",
    "        print(f'Running TfidfVectorizer + MultinomialNB')\n",
    "        print('--------------------------------------- \\n')\n",
    "        # Set up pipeline params\n",
    "        pipe4 = Pipeline([\n",
    "        ('tvec', TfidfVectorizer(stop_words = 'english')),\n",
    "        ('mnb', MultinomialNB())\n",
    "        ])\n",
    "\n",
    "\n",
    "        # Set up pipeline params\n",
    "        pipe_params = {\n",
    "            'tvec__max_features': [200, 500],\n",
    "            'tvec__ngram_range' : [(1, 2)],\n",
    "#             'mnb__alpha': [10.0, 0, .01], \n",
    "            'mnb__fit_prior': [True, False]\n",
    "        }\n",
    "        \n",
    "        gs4 = GridSearchCV(pipe4,\n",
    "        pipe_params,\n",
    "        cv = 5) # 5-fold cross-validation.\n",
    "        \n",
    "        # Fit GridSearch to training data.\n",
    "        gs4.fit(self.X_train, self.y_train);\n",
    "        gs4_model = gs4.best_estimator_\n",
    "        preds4 = gs4_model.predict(self.X_test)\n",
    "        print('4 of 4  Models Finished \\n')\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "        # ---------------------------------------\n",
    "        # Output\n",
    "        print('Model Metrics:')\n",
    "        print('-------------- \\n')\n",
    "        \n",
    "        print(f'CountVectorizer & LogisticRegression \\n')\n",
    "        print(f'Best Score: {gs1.best_score_} \\n')\n",
    "\n",
    "        print(f'X_train, y_train Score: {gs1_model.score(self.X_train, self.y_train)}')\n",
    "        print(f'X_test, y_test Score: {gs1_model.score(self.X_test, self.y_test)} \\n')\n",
    "\n",
    "        cm = confusion_matrix(self.y_test, preds1)\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        print(f'True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN} \\n')\n",
    "\n",
    "        print(f'{classification_report(self.y_test, preds1)} \\n')\n",
    "\n",
    "        print('--------------------------------- \\n')\n",
    "\n",
    "        \n",
    "        print(f'CountVectorizer & MultinomialNB \\n')\n",
    "\n",
    "        print(f'Best Score: {gs2.best_score_} \\n')\n",
    "\n",
    "        print(f'X_train, y_train Score: {gs2_model.score(self.X_train, self.y_train)}')\n",
    "        print(f'X_test, y_test Score: {gs2_model.score(self.X_test, self.y_test)} \\n')\n",
    "\n",
    "        cm = confusion_matrix(self.y_test, preds2)\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        print(f'True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN} \\n')\n",
    "\n",
    "        print(f'{classification_report(self.y_test, preds2)} \\n')\n",
    "\n",
    "        print('------------------------------------- \\n')\n",
    "\n",
    "        \n",
    "        print(f'TfidfVectorizer & LogisticRegression \\n')\n",
    "\n",
    "        print(f'Best Score: {gs3.best_score_} \\n')\n",
    "\n",
    "        print(f'X_train, y_train Score: {gs3_model.score(self.X_train, self.y_train)}')\n",
    "        print(f'X_test, y_test Score: {gs3_model.score(self.X_test, self.y_test)} \\n')\n",
    "\n",
    "        cm = confusion_matrix(self.y_test, preds3)\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        print(f'True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN} \\n')\n",
    "\n",
    "        print(f'{classification_report(self.y_test, preds3)} \\n')\n",
    "\n",
    "        print('-------------------------------- \\n')\n",
    "        \n",
    "        print(f'TfidfVectorizer & MultinomialNB \\n')\n",
    "\n",
    "        print(f'Best Score: {gs4.best_score_} \\n')\n",
    "\n",
    "        print(f'X_train, y_train Score: {gs4_model.score(self.X_train, self.y_train)}')\n",
    "        print(f'X_test, y_test Score: {gs4_model.score(self.X_test, self.y_test)} \\n')\n",
    "        cm = confusion_matrix(self.y_test, preds4)\n",
    "        TP = cm[1][1]\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        print(f'True Positives: {TP}, True Negatives: {TN}, False Positives: {FP}, False Negatives: {FN} \\n')\n",
    "\n",
    "        print(f'{classification_report(self.y_test, preds4)} \\n')\n",
    "        print('------------------ \\n')\n",
    "\n",
    "        print('>----- Analysis Complete, Thank You For Flying With Us! -------> \\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an analyzer object\n",
    "a = analyzer(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Analysis, Be Patient... \n",
      "\n",
      "Running CountVectorizer + LogisticRegression\n",
      "-------------------------------------------- \n",
      "\n",
      "1 of 4  Models Finished \n",
      "\n",
      "I Said Be Patient!!! \n",
      "\n",
      "Running CountVectorizer + MultinomialNB\n",
      "--------------------------------------- \n",
      "\n",
      "2 of 4  Models Finished \n",
      "\n",
      "Running TfidfVectorizer + LogisticRegression\n",
      "-------------------------------------------- \n",
      "\n",
      "3 of 4  Models Finished \n",
      "\n",
      "Running TfidfVectorizer + MultinomialNB\n",
      "--------------------------------------- \n",
      "\n",
      "4 of 4  Models Finished \n",
      "\n",
      "Model Metrics:\n",
      "-------------- \n",
      "\n",
      "CountVectorizer & LogisticRegression \n",
      "\n",
      "Best Score: 0.7875053720013876 \n",
      "\n",
      "X_train, y_train Score: 0.8950418544752092\n",
      "X_test, y_test Score: 0.7862745098039216 \n",
      "\n",
      "True Positives: 1092, True Negatives: 111, False Positives: 254, False Negatives: 73 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.30      0.40       365\n",
      "           1       0.81      0.94      0.87      1165\n",
      "\n",
      "    accuracy                           0.79      1530\n",
      "   macro avg       0.71      0.62      0.64      1530\n",
      "weighted avg       0.76      0.79      0.76      1530\n",
      " \n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "CountVectorizer & MultinomialNB \n",
      "\n",
      "Best Score: 0.7714074902527299 \n",
      "\n",
      "X_train, y_train Score: 0.8019961365099807\n",
      "X_test, y_test Score: 0.765359477124183 \n",
      "\n",
      "True Positives: 1048, True Negatives: 123, False Positives: 242, False Negatives: 117 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.34      0.41       365\n",
      "           1       0.81      0.90      0.85      1165\n",
      "\n",
      "    accuracy                           0.77      1530\n",
      "   macro avg       0.66      0.62      0.63      1530\n",
      "weighted avg       0.74      0.77      0.75      1530\n",
      " \n",
      "\n",
      "------------------------------------- \n",
      "\n",
      "TfidfVectorizer & LogisticRegression \n",
      "\n",
      "Best Score: 0.7865422951261061 \n",
      "\n",
      "X_train, y_train Score: 0.8103670315518352\n",
      "X_test, y_test Score: 0.7764705882352941 \n",
      "\n",
      "True Positives: 1125, True Negatives: 63, False Positives: 302, False Negatives: 40 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.17      0.27       365\n",
      "           1       0.79      0.97      0.87      1165\n",
      "\n",
      "    accuracy                           0.78      1530\n",
      "   macro avg       0.70      0.57      0.57      1530\n",
      "weighted avg       0.75      0.78      0.73      1530\n",
      " \n",
      "\n",
      "-------------------------------- \n",
      "\n",
      "TfidfVectorizer & MultinomialNB \n",
      "\n",
      "Best Score: 0.775270671202448 \n",
      "\n",
      "X_train, y_train Score: 0.7817128139085641\n",
      "X_test, y_test Score: 0.7784313725490196 \n",
      "\n",
      "True Positives: 1154, True Negatives: 37, False Positives: 328, False Negatives: 11 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.10      0.18       365\n",
      "           1       0.78      0.99      0.87      1165\n",
      "\n",
      "    accuracy                           0.78      1530\n",
      "   macro avg       0.77      0.55      0.53      1530\n",
      "weighted avg       0.78      0.78      0.71      1530\n",
      " \n",
      "\n",
      "------------------ \n",
      "\n",
      ">----- Analysis Complete, Thank You For Flying With Us! -------> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the analysis method and enjoy the results\n",
    "a.do_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
